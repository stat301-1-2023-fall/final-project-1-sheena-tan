---
title: "Progress Memo 2"
subtitle: |
  | Final Project 
  | Data Science 1 with R (STAT 301-1)
author: "Sheena Tan"
date: today

format:
  html:
    toc: true
    embed-resources: true

execute:
  echo: false
  warning: false
  
from: markdown+emoji 
---

::: {.callout-tip icon=false}

## Github Repo Link

[https://github.com/stat301-1-2023-fall/final-project-1-sheena-tan.git](https://github.com/stat301-1-2023-fall/final-project-1-sheena-tan.git)

:::

## Updated Data Memo

### Data Source

I am using data from Northwestern's Course and Teacher Evaluation Council (CTEC) system, which is data available to students at Northwestern University. These evaluations provide ratings made by previous students regarding various courses and their instructor, including information like how much time the student spent on the course, what degree requirements the course fulfilled for the student, what year and school the student is in, and how they would rate the instruction and the course across several categories. 

As discussed with Professor Sass, I finished scraping data from the most recent academic year (2022-23) across various undergraduate courses, organizing the data by school and department. I took data from six representative departments, for each of the six Northwestern schools. 

1. Psychology (PSYCH) for Weinberg,
2. Civil and Environmental Engineering (CIV_ENV) for McCormick,
3. Music (MUSIC) for Bienen, 
4. Communication Studies (COMMS) for the School of Communications,
5. Journalism (JOUR) for Medill,
6. and School of Education & Social Policy Core (SESP) for SESP.


### Data Description

The data has a total of 5137 objects across 12 variables.

1. `school`: categorical variable; the school the department is from,
-  `mcmk` for McCormick, 
-  `jour` for Medill, 
-  `comm` for Comms,
-  `bien` for Bienen,
-  `sesp` for SESP,
-  and `wnbg` for Weinberg
2. `dept`: categorical variable; the department the course is offered through, 
-  `psych` for Psychology,
-  `sesp` for SESP Core, 
-  `music` for Music, 
-  `comm_st` for Communication Studies , 
-  `jour` for Journalism, 
-  and `civ_env` for Civil and Environmental Engineering
3. `course_num`: the three digit course number
4. `course_term`: categorical variable; the quarter the course was offered, 
-  `fall` for Fall 2022,
-  `winter` for Winter 2023, 
-  and `spring` for Spring 2023
5. `instructor`: the name of the instructor
6. `inst_rating`: the mean of students' responses to the prompt, "Provide an overall rating of the instruction." rated out of 6
7. `course_rating`: the mean of students' responses to the prompt, "Provide an overall rating of the course" rated out of 6
8. `learn_rating`: the mean of students' responses to the prompt, "Estimate how much you learned in the course." rated out of 6
9. `challenge_rating`: the mean of students' responses to the prompt, "Rate the effectiveness of the course in challenging you intellectually." rated out of 6
10. `interest_rating`: the mean of students' responses to the prompt, "Rate the effectiveness of the instructor in stimulating your interest in the subject." rated out of 6
11. `hours_spent`: the mean of students' reponses to the prompt, "Estimate the average number of hours per week you spent on this course outside of class and lab time."
12. `essay`: text responses to the prompt, "Please summarize your reaction to this course focusing on the aspects that were most important to you."

### Data Preparation
For time limitations during data scraping, the raw data did repeat values for each student essay response. Instead, the first instace of every class had the complete data entered, but following entries for that class were left empty. 

To address these missing values, cleaning occured in three main steps: First, string values were changed to be missing values when empty. Second, missing values were filled from the nearest values above. Finally, the data was examined for missingess and no remaining missingness (other than in the `essay` responses) was found. 

## EDA

### The Background
In the four years that I've been at Northwestern, I've heard my fair share of anecdotes, stereotypes, and stories about the students and classes in the different schools. *SESP classes are easy, but students don't learn anything*; or *McCormick kids never leave their dorms because of how long they have to study*; or this or that class is really great, or this or that professor is really horrible. 

However, CTECs do not provide a built-in mechanism to compare data across courses or across teachers, in a department or across departments. This project wanted to compare data across schools and classes to investigate any patterns that may be of interest, like:

- Which school learns the most from their classes?
- Which school spends the most time on their classes?
- Does putting in more time make the class more rewarding?
- Which school has the best professors? Best classes?
- Does having a better professor influence how much students feel that they learn?
- Who is the most liked and most hated teacher in each department?
- Which classes have the most opinionated CTECs, either good or bad?
- For classes with more than one teacher, who taught it best?
- What are the best classes overall and in each department? 
- What comparisons can we make by level (100-200-300)? 

### Here is what I found.

**Which school spends the most time on their classes?**

![Hours Spent Studying By School](figures/schools_hours_spent.png)

We can see that McCormick students spend **significantly more** hours on average (7.41h) than students from other schools. Medill (5.63h) and Bienen (5.69h) students spend more time than students from other schools (\<5h).

**Which school learns the most from their classes?**

![Amount Learned By School](figures/schools_amount_learned.png)

The differences in ratings here are less drastic, with students from all schools answering an average of 4+ on a 1 to 6 scale. However, McCormick students **learned the most** on average, being the only school with an average rating greater than 5.

**Does putting in more time make the class more rewarding?** 

![Time Spent Versus Amount Learned](figures/time_learning_scatterplot.png)

It seems that a relationship does exist. For example, ***NONE*** of the courses that required less than 10 hours of work had a learning rating of less than 3.5. At the same time, higher learning ratings were spread across the board, with some classes requiring minimal hours of work and still others requiring over 13 hours on average. In other words, it doesn't take a lot of time to feel like you learned a lot, but if it does take time, you'll feel like you learned from it.

Notably, *McCormick* classes were the only ones requiring **over 12.5 hours** of work. *SESP* classes were the only ones with a learning rating of **less than 2.**

## Progress Summary
For this progress memo, I completed over 10 hours of data collection, cleaned the data, and am currently exploring the fourth of the ten questions I was interested in, described above. For the remaining questions, my next steps will be as follows:

- Does putting in more time make the class more rewarding?: **Break up the total plot to look at each school in its own plot**
- Which school has the best professors? Best classes?: **define a new instructor measure using the inst_rating and interest_rating**, then **take the means of the new instructor rating and course_rating for each school and compare using bar plots**, also **filter for positive and negative affect codewords to complete a sentiment analysis on the CTECs** in order to better inform the course ratings
- Which school is the best overall? **make radar plots for each school**
- Does having a better professor influence how much students feel that they learn? **use the new instructor measure and compare to learn_rating using a scatterplot** 
- Who is the most liked and most hated teacher in each department? **use the new instructor rating to find which teachers have the highest and lowest ratings**
- Which classes have the most opinionated CTECs, either good or bad? **see which sentiment analyses are the most positive and most negative**
- For classes with more than one teacher, who taught it best? **filter for classes with unique instructor values but same course and department numbers**, then **compare instructor ratings**
- What are the best classes overall and in each department? **create enjoyment rating based on combination of inst_rating, course_rating, learn_rating, and interest_rating**, consider including challenge_rating, then **find teachers with the highest enjoyment ratings** in each department and overall
- What comparisons can we make by level (100-200-300)? **group .by level and run analyses that may be of interest for these groups**, like if students feel like they learn more depending on level for example 

I think my progress is in great shape. I estimate I still have about 10 hours of work left. This project was very heavy on data collection, as you know. 